#### Raft

之前学习MIT6.824的时候已经学习实现过raft了，但是时间过了挺久又忘了很多内容了，刚好tinyKV project2也是实现一个raft，就趁机复习并记录一下。



### CAP理论

在学习Raft之前，先看看**CAP理论**（Consistency-Availability-Partition tolerance Theory）

#### C：Consitency，一致性

该项强调数据的正确性. 具体而言，每次读操作，要么读到最新，要么读失败. 这要求整个分布式系统像是一个不可拆分的整体，写操作作用于集群像作用于单机一样，具有广义的“原子性”.

#### A：Availability，可用性

该项站在使用者的角度，强调使用服务的体验.客户端的请求能够得到响应，不发生错误，也不能出现过长的等待时间.

#### P：Partition tolerance，分区容错性

分区容错性强调的是，在网络环境不可靠的背景下，整个系统仍然是正常运作的，不至于出现系统崩溃或者秩序混乱的局面.

对于这三个性质，最多只能满足两个，所以在设计的时候需要tradeoff

对于一个分布式系统 P是必须要满足的，因此我们需要考虑到底是满足高可用还是强一致性。



#### C的问题

对于**即时一致性问题**，如果server端是异步的，那么client可能从某些节点中读到老数据。

试想一个场景：

I 当前集群的服务端有 master 和 follower 两个节点.

II 客户端写请求打到了 master，写入 x = 3 这一项内容；

III 紧接着，客户端读请求打到了 follower，查询 x = 3 的值.

那么在第（3）步中所取得的 x 的值会是多少呢？答案是不确定的. 因为这取决于 master 和 follower 之间数据同步的机制.

倘若，为了满足更快响应客户端的诉求，服务端采用了异步完成数据同步任务的机制，那么客户端的读请求就可能在 follower 同步到 set x = 3 这一项任务之前就打到 follower，此时会取到 x 的老数据或者 x 不存在的响应，总之，读到的数据和客户端期待的结果产生了差距.

以上，就是分布式系统中的即时一致性问题.



对于**顺序一致性问题**

现在请试想另一种场景：

**I 客户端依次向 master 发送了 set x = 3、set x = 4 的两笔请求；**

**II master 在本机依次完成了两笔写操作，于是状态机中记录的结果为 x = 4；**

**III 同时，master 异步开启将请求同步到 follower 的任务，任务发出的顺序也是 ① set x = 3 ② set x = 4；**

**IV 由于网络问题，第 ① 笔请求出了点状况，导致第 ② 笔请求后发先至，第 ① 笔请求随后而至；**

**V 于是 follower 先执行 ② set x = 4，后执行 ① set x = 3，最终 follower 状态机内的结果为 x = 3.**

这个问题相比场景（1）就更严重了，因为 follower 中已经记录了错误的数据，接下来不论何时面对客户端的读请求都会返回这个错误的结果. 这种情况下，我们就称分布式系统的最终一致性也遭到了破坏.



#### A的问题

（1）倘若集群中某个 follower 出现宕机, master 同步数据时会因为未集齐所有 follower 的响应, 而无法给客户端 ack，这样一个节点的问题就会被放大到导致整个系统不可用；

（2）倘若某个 follower 的网络环境或者本机环境出现问题，它给出同步数据响应的时间出乎意料的长，那么整个系统的响应效率都会被其拖垮，这就是所谓的木桶效应.

### 术语表

| **中文术语** | **英文术语**          | **含义**                                                     |
| ------------ | --------------------- | ------------------------------------------------------------ |
| 领导者       | leader                | 节点的三种角色之一. 集群的首脑，负责发起”提议“、”提交“被多数派认可的决断. |
| 跟随者       | follower              | 节点的三种角色之一. 需要对 leader 的 ”提议“ 、”提交“和 candidate 的 ”竞选“ 进行响应. |
| 候选人       | candidate             | 节点的三种角色之一. 是一种处于竞选流程中的临时状态，根据多数派投票的结果会切为 leader 或 follower 的稳定态. |
| 最终一致性   | finnal consistency    | 中强一致性. 对于写请求，服务端保证最终一定能提供出正确的结果，但需要同步时间. 同步期间，可能被读到不一致的老数据. |
| 即时一次性   | immediate consistency | 强一致性. 服务端要求做到写入立即可读.                        |
| 预写日志     | write ahead log       | 记录写请求明细的日志.（单指 raft 算法下狭义的预写日志）      |
| 状态机       | state machine         | 节点内存储数据的介质.                                        |
| 提议         | proposal              | 两阶段提交的第一个阶段. 指的是 leader 向所有节点发起日志同步请求的过程. |
| 提交         | commit                | 两阶段提交的第二个阶段. 指的是 leader 认可一笔写请求已经被系统采纳的动作. |
| 应用         | apply                 | 指的是将预写日志记录内记录的写操作应用到状态机的过程.        |
| 任期         | term                  | 任期是用于标识 leader 更迭的概念. 每个任期内至多只允许有一个 leader. |
| 日志索引     | index                 | 日志在预写日志数组中的位置.                                  |
| 脑裂         | brain split           | 同一任期内，集群出现两个 leader，导致秩序崩盘.               |



### Raft 一主多从 读写分离

raft中很多方面都遵循多数派原则，即系统的决断无需全员参与,多数派达成的共识即可视为整个系统的答复。

多数派原则是提高分布式系统可用性 A 的关键. 对于整个系统而言，执行一项操作要求全员共同响应以实现强 C 的保证是过于苛刻的，因为我们无法保证所有节点都能健康运作。

尽量保持节点个数为**奇数**。

**一主多从**： raft中分为leader和follower两类角色（先不管candidate），

leader拥有更广阔的视野，需要总览全局，领导一些日常事务的推进；

follower 职责相对简单但同样重要，因为这是一个基于多数派原则运作的民众团体，所有角色只要拧成一股绳，聚成了多数派，就能代表整个系统进行决断，甚至包括推翻 leader.

**读写分离**： 

读操作可以由集群的任意节点提供服务；

写操作统一需要由 leader 收口处理，并向 follower 同步. 倘若 follower 率先收到了来自客户端的写请求，也需要转发给 leader 进行处理.

这种读写分离的机制，通过读操作的负载均衡提高了系统整体的吞吐量，也通过写操作的统一收口降低了共识算法的复杂度，但与此同时也衍生出两个问题：

（1）读操作可由任意节点提供服务，那么倘若一个存在数据状态滞后的 follower 提供了服务，那么客户端就可能读到老数据. 因此到此为止，raft 只能保证到数据的最终一致性，而无法满足即时一致性. 

（2）集群一主多从，纵览全局. 倘若 leader 出了问题，群龙无首，系统岂不是会分崩离析吗？针对这个问题，raft 建立了一套完善的领导者选举机制，保证在 leader 不可用时会有替补席的 follower 挺身而出，改朝换代成为新的 leader，保证系统的正常运作。



### 状态机与预写日志

状态机 （state machine）是节点实际存储数据的容器,写请求的最后一步是将结果写入状态机，而读请求也需要从状态机中获取数据进行响应.

预写日志（write ahead log，简称 wal）是通过日志的方式记录下每一笔写请求的明细（例如 set x = 3 这样一笔记录），使得变更历史有迹可循. 在 raft 算法中，写请求会先组织成预写日志的形式添加到日志数组中，当一个日志（写请求）达到集群多数派的认可后，才能够被提交，将变更应用到状态机当中.

预写日志的设计是为了解决顺序一致性问题的：

预写日志由一个数组承载，为一段时间内的多笔写请求提供了一个缓存区；同时，每笔预写日志是一笔写请求的抽象，通过其记录的明细，使得我们可以对写请求的内容进行比较. 这样的机制之下，我们只要保证预写日志数组中，被准许应用到状态机的部分每笔预写日志的内容都完全相同，这样就能解决写请求乱序的问题，从而达成数据的最终一致性.



### 两阶段提交

->leader接收到一个写请求 
->leader将写请求添加到本地的预写日志中，并向其他节点广播同步这笔写请求，这个过程就称为proposal
->follower收到同步请求后通过一套校验机制来判断是否执行同步并返回响应
->若leader收到半数以上的节点同意并完成了他们本地的预写日志的操作，那么leader此时会commit这个请求，并返回ack给client表示已经成功处理请求。
->其他节点随后会通过与leader的其他交互方式中得到这个commit操作信息（etcd中使用heartbeat），最终commit操作被follower也执行。
->已经commit的预写日志具备了被apply到状态机中的资格，但apply的时机取决于实现方式，倘若只追求最终一致性，可以选择异步应用；倘若追求立即一致性，则会要求 leader 先应用到状态机，才能给予客户端 ack。

整个流程分为proposal和commit两个阶段，所以称之为两阶段提交

这里有个**小思考点**： 所有已经被commit的请求，从client视角来看，它已经被系统接收采纳，那么系统自身就应当完成这个最终一致性的任务。如果leader在收到来自follower同意将请求添加到预写日志之后，在leader本地实现了commit，然而此时leader突然宕机（意味着leader还没能将commit信息发送给follower）。那么此时，需要进行重新选举，由于此前大多数节点都已经将该笔请求写入到预写日志了，所以未写入的节点不会获得这些此前已经将请求写入到预写日志的节点的投票，因而他们无法成为新的leader。而新的leader一旦上任，他们就会去commit这些上个leader未commit的预写日志，并将这些commit信息发送给follower，以完成最终一致性。

### 领导者选举

国一日不可无君，家一日不可无主，raft不可一日无leader

leader是写请求的入口，所以如果leader寄了，必须要有一个选举机制来让follower成为新的leader，以保证集群的正常运作。

（1）follower 如何感应到 leader 挂了，从而主动进行补位？

leader 需要定期向 follower 发送心跳，证明自己仍然健在。与之对应的，follower 会建立一个心跳检测定时器，当超过指定时长未收到 leader 的心跳，则认为 leader 已死，会切换成候选人（candidate）发起竞选，尝试补位成为新的 leader。

（2）什么样的 follower 有资格补位成为 leader？

follower 成为 candidate 后,会广播向所有节点拉票，当投赞同票的节点数（包括candidate 本身）达到多数派的时候，该 candidate 会胜任，成为新的 leader. 

### 任期与日志索引

term就是一个任期，term是全局增大的，每一个任期中最多只有一个leader（也可能竞选失败而导致一个任期无leader），每次转换leader的时候，对应的term都会增大。

每当一个candidate发起一轮campaign（竞选）的时候，他都会在自己的term上自增1，相当于告诉其他人，自己要改朝换代了。

节点中的预写日志存放在一个数组中，每则日志在数组中的位置称之为索引 index.

于是，每一则预写日志会有两个核心的标识属性：

（1）term：标志了这则日志是哪个任期的 leader 在位时同步写入的；

（2）index：标志了这则日志在预写日志数组的位置.

通过 {term , index} 二元组可以组成一个全局唯一键，定位到一则日志，并且能够保证位于不同节点中日志，只要其 term 和 index 均相同，其内容一定完全一致。



### 角色定义及切换

raft 算法中，集群节点的角色类型分为：领导者 leader、跟随者 follower、候选人 candidate 三种角色.

（1）leader -> follower

倘若 leader 发现当前系统中出现了更大的任期，则会进行“禅让”，主动退位成 follower.

这里 leader 发现更大任期的方式包括：I 向 follower 提交日志同步请求时,从 follower 的响应参数中获得; II 收到了来自新任 leader 的心跳或者同步日志请求；III 收到了任期更大的 candidate 的拉票请求.

（2）follower -> candidate

leader 需要定期向 follower 发送心跳，告知自己仍健在的消息.

倘若 follower 超过一定时长没收到 leader 心跳时，会将状态切换为 candidate ，在当前任期的基础上加 1 作为竞选任期，发起竞选尝试补位.

（3）candidate -> follower

candidate 参与竞选过程中，出现以下两种情形时会退回 follower：

I 多数派投了反对票；

II 竞选期间，收到了任期大于等于自身竞选任期的 leader 传来的请求.

（4）candidate -> leader

candidate 竞选时，倘若多数派投了赞同票，则切换为 leader.

（5）candidate -> candidate

candidate 的竞选流程有一个时间阈值. 倘若超时仍未形成有效结论（多数派赞同或拒绝），则会维持 candidate 身份，将竞选任期加1，发起新一轮竞选.

#### Leader

1. 定期广播心跳请求。 让 follower 重置心跳检测定时器，避免其切换成 candidate 发起竞选，在心跳请求中携带上 leader 最新已提交日志的标识 id（term + index），推动 follower 更新日志提交进度。

   etcd中 follower会回复心跳请求，让leader来判断自己的地位是否正常。

2. propose log synchronization， 广播proposal，开启两阶段提交流程。

#### Follower

follower的职责：

（1）负责同步 leader 传来的写请求，此时也有一个参与民主反馈的过程，倘若同步成功，会给予 leader 正向反馈，当 leader 的同步请求收到半数以上的认可时，会提交日志；

（2）通过接收 leader 心跳的方式，获取到携带的 commitIndex 信息，及时完成已被多数派认可的预写日志的提交，以推进其写入状态机的进度. 这一项相当于做到了数据的备份，也被读请求最终一致性提供了保证;

（3）负责为参与竞选 candidate 的投票

（4）通过心跳检测定时器时时关注 leader 的健康状态，当超时未收到心跳时，会切换为 candidate 发起竞选.

#### Candidate

candidate 是一个临时态，成为 candidate 意味着此时正处于成与败的分叉路口，candidate 有关的核心流程如下：

（1）倘若 follower 切为 candidate，会将当前任期加1，作为竞选任期；

（2）会将自身的一票投给自己；

（3）广播向所有节点拉票；

（4）倘若拉票请求超时前，得到多数派认可，则上位为 leader；

（5）倘若拉票请求超时前，遭到多数派拒绝，则老实退回 follower；

（6）倘若拉票请求超时前，收到了任期大于等于自身竞选任期的 leader 的请求，则老实退回 follower；

（7）倘若拉票请求超时，则竞选任期加 1，发起新一轮竞选拉票请求.



### 外部请求链路梳理

（1）写操作需要由 leader 统一收口. 倘若 follower 接收到了写请求，则会告知客户端 leader 的所在位置（节点 id），让客户端重新将写请求发送给 leader 处理；

（2）leader 接收到写请求后，会先将请求抽象成一笔预写日志，追加到预写日志数组的末尾；

（3）leader 会广播向集群中所有节点发送同步这笔日志的请求，称之为第一阶段的“提议”；

（4）follower 将日志同步到本机的预写日志数组后，会给 leader 回复一个“同步成功”的ack；

（5）leader 发现这笔请求对应的预写日志已经被集群中的多数派（包括自身）完成同步时，会”提交“该日志，并向客户端回复“写请求成功”的 ack.

上面描述了一个最理想化的写流程链路，其中还存在几个场景需要进行补充：

case 1：leader 任期滞后.

在第（4）步中，倘若 follower 发现当前 leader 的 term 小于自己记录的最新任期，本着”前朝的剑不斩本朝官“的原则，follower 会拒绝 leader 的这次同步请求，并在响应中告知 leader 当前最新的 term；leader 感知到新 term 的存在后，也会识相地主动完成退位.

case 2：follower 日志滞后.

同样在第（4）步中，此时虽然 leader 的 term 是最新的，但是在这笔最新同步日志之前， follower 的预写日志数据还存在缺失的数据，此时 follower 会拒绝 leader 的同步请求；leader 发现 follower 响应的任期与自身相同却又拒绝同步，会递归尝试向 follower 同步预写日志数组中的前一笔日志，直到补齐 follower 缺失的全部日志后，流程则会回归到正常的轨道.

case 3：follower 日志”超前“.

同样在第（4）步中，leader 的 term 是最新的，但是 follower 在 leader 最新同步日志的索引及其之后已存在日志，且日志内容还与当前 leader 不一致. 此时 follower 需要移除这部分”超前“的日志，然后同步 leader 传送的日志，向当前在任 leader 看齐.

case 4：如何将最终一致性升级到即时一致性？

标准的 raft 算法模型中，在 C 方面只能做到”最终一致性“的语义. 倘若想要升级为”即时一致性“，就需要在写流程和读流程中都做些额外的处理.

在写流程第（5）步中，leader 不仅需要提交这笔写请求对应的预写日志，还需要确保将这笔日志应用到状态机中，才能给予客户端”请求成功“的 ack，以此保证读 leader 状态机时，能读取到最新的数据.

如果要求读流程满足即时一次性的要求，则要做一些额外的处理：

（1）appliedIndex 校验：每次 leader 处理写请求后，会把最晚一笔应用到状态机的日志索引 appliedIndex 反馈给客户端. 后续客户端和 follower 交互时，会携带 appliedIndex. 倘若 follower 发现自身的 appliedIndex 落后于客户端的 appliedIndex，说明本机存在数据滞后，则拒绝这笔请求，由客户端发送到其他节点进行处理.

（2）强制读主：follower 收到读请求时，也统一转发给 leader 处理. 只要 leader 处理写请求时，保证先写状态机，后给客户端响应，那么状态机的数据可以保证即时一致性. 但是这样的弊端就是 leader 的压力过大，其他 follower 节点只沦为备份数据副本的配角.

同时，这种强制读主的方案还存在一个问题，就是领导者在处理读请求时，需要额外对自己做一次合法性身份证明. 这是因为倘若当前网络出现分区情况，外界早已更换朝代，而 leader 仍坐落于小分区中不知大清已亡，固执地认为自己是正统，那么此时提供的读服务就无法保证即时一致性，会退化为最终一致性.

解决这个问题的方案是，leader 提供读服务时，需要额外向集群所有节点发起一轮广播，当得到多数派的认可，证明自己身份仍然合法时，才会对读请求进行响应.

这个 leader 身份合法校验的问题只存在于读请求中而不影响写请求，这是因为 leader 处理写流程时，在提议阶段就必须与外界通信，获取多数派的反馈.这个反馈的过程实际上就已经完成了对 leader 身份合法性的校验.

### 内部请求链路梳理

#### 日志同步请求

（1）请求起点：领导者

（2）请求意图：领导者向其他节点同步预写日志(proposal).

（3）请求参数：

| **字段**     | **说明**                                                  |
| ------------ | --------------------------------------------------------- |
| term         | 领导者的任期                                              |
| leaderID     | leader 的节点 id，方便后续 follower 转发写请求            |
| leaderCommit | leader 最新提交的日志 index，方便 follower 更新数据进度   |
| prevLogIndex | 当前同步日志的前一条日志的 index.                         |
| prevLogTerm  | 当前同步日志的前一条日志的 term.                          |
| log[]        | 同步的日志，可能为多笔，因为 follower 可能滞后了多笔日志. |

（4）请求终点：

终点1：leader

处理方式：

I 倘若该任期小于自身，拒绝，并回复自己的最新任期；

II 倘若该任期大于自身，退位为 follower,按照 follower 的模式处理该请求.

 

终点2：follower

处理方式：

I：倘若 leader 任期落后于自己，拒绝请求，并回复自己所在的任期；

II：倘若 follower 存在不一致的日志，则删除多余的日志，同步 leader 日志与之保持一致；

III：倘若 follower 存在日志滞后，则拒绝请求，让 leader 重发更早的日志，直到补齐所有缺失.

 

终点3：candidate

I：倘若 leader 任期大于等于自己，退回 follower，按照 follower 模式处理请求；

II：如果 leader 任期小于自己，拒绝，并回复自己的最新任期.

 

（5）响应参数：

| **字段**  | **说明**               |
| --------- | ---------------------- |
| term      | 节点当前的任期         |
| success   | 同步日志的请求是否成功 |
| needIndex | 为了需要补全的log      |

（6）leader 后处理

倘若多数派都完成了日志同步，leader 会提交这笔日志；

倘若某个节点拒绝了同步请求，并回复了一个更大的任期，leader 会退位回 follower，并更新任期；

倘若某个节点拒绝了同步请求，但回复了相同的任期，leader 会递归发送前一条日志给该节点，直到其接受同步请求为止；

倘若一个节点超时未给 leader 回复，leader 会重发这笔同步日志的请求.



#### 心跳&提交同步请求

（1）请求起点：领导者

（2）请求意图：周期性发送心跳证明自己还健在；同时日志提交的进度.

（3）请求参数：

| **字段**     | **说明**                                                |
| ------------ | ------------------------------------------------------- |
| term         | 领导者的任期                                            |
| leaderID     | leader 的节点 id，方便后续 follower 转发写请求          |
| leaderCommit | leader 最新提交的日志 index，方便 follower 更新数据进度 |

（4）请求终点：

终点1：leader

处理方式：

I 倘若该任期小于自身，直接无视；

II 倘若该任期大于自身，退位为 follower,按照 follower 的模式处理该请求.

 

终点2：follower

处理方式：

I 倘若任期小于自身，直接无视

II 重置 leader 心跳检测计时器. 查看 leaderCommit, 看是否有预写日志可以被提交.

 

终点3：候选人

处理方式：

I 倘若任期小于自身，直接无视

II 如果任期大于等于自己，退回 follower，按照 follower 模式处理请求.

 

注意，心跳请求是单向非阻塞的，leader 发送心跳后无需等待其他节点的回复.

#### 竞选拉票请求

（1）请求起点：候选人

（2）请求意图：拉票，希望得到多数派认同，上位成为 leader

（3）请求参数：

term：当前竞选领导者的任期；

candidateID：候选人的节点 ID；

lastLogIndex：候选人最后一笔预写日志的索引；

lastLogTerm：候选人最后一笔预写日志的任期.

 

| **字段**     | **说明**                                                |
| ------------ | ------------------------------------------------------- |
| term         | candidate 的竞选任期，如果上位了，就采用此任期          |
| candidateID  | candidate 的节点 id，方便 follower 标记自己将票投给了谁 |
| lastLogIndex | candidate 最晚一笔预写日志的 index                      |
| lastLogTerm  | candidate 最晚一笔预写日志的 term                       |

（4）请求终点：

终点1：leader

处理方式：

I 倘若 candidate 的竞选任期小于自身，拒绝，并回复自己的最新任期；

II 倘若 candidate 的竞选任期大于自身，退位为 follower,按照 follower 的模式处理该请求.

 

终点2：follower

处理方式：

I：倘若 candidate 的竞选任期小于自身，拒绝，并回复自己的最新任期；

II：倘若自己已经将票投给了其他 candidate，拒绝；

III：倘若自己已经将票投给了这个 candidate，接受；（candidate 侧会幂等去重）

IV：倘若 candidate 的 lastLogTerm 大于自己最后一笔预写日志的 term，接受；

V：倘若 candidate 的 lastLogTerm 小于自己最后一笔预写日志的 term，拒绝；

VI：倘若 candidate 的 lastLogTerm 等于自己最后一笔预写日志的 term，且 candidate 的 lastLogIndex 大于等于自己最后一笔预写日志的 index，接受；

VII：倘若 candidate 的 lastLogTerm 等于自己最后一笔预写日志的 term，且 candidate 的 lastLogIndex 小于自己最后一笔预写日志的 index，拒绝.



终点3：candidate

I：倘若 candidate 的竞选任期小于等于自己的竞选任期，拒绝；

II：倘若 candidate 的竞选任期大于自己的竞选任期，退回 follower，按照 follower 的模式处理.



（5）响应参数：

| **字段** | **说明**       |
| -------- | -------------- |
| term     | 节点当前的任期 |
| granted  | 是否投了赞同票 |

（6）candidate 后处理

I 倘若多数派投了赞同票（包括自己），晋升为 leader，竞选任期则为新的国号；

II 倘若多数派投了反对票，则退回 follower；

III 倘若反对票中，出现了比自己更高的任期，退回 follower，更新任期；

IV 倘若形成多数派决议前，收到了任期大于等于自己的 leader 的请求，退回 follower，更新任期；

V 倘若拉票请求超时，则自增竞选任期，发起新一轮竞选.

 

（7）小结

在第（4）部分，通过 follower 决定投票的判断机制，可以看出，follower 只愿意将票投给数据状态不滞后于自己的 candidate. 又由于 candidate 要获取多数派的赞同票才能上位成为 leader，换言之，只有数据一致性状态在多数派中处于领先地位的 candidate 才有资格成为 leader. 这一项机制非常重要，正是由它保证了”两阶段提交，提交即可响应“这一流程的合理性.

