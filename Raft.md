# Raft

之前学习MIT6.824的时候已经学习实现过raft了，但是时间过了挺久又忘了很多内容了，刚好tinyKV project2也是实现一个raft，就趁机复习并记录一下。



### CAP理论

在学习Raft之前，先看看**CAP理论**（Consistency-Availability-Partition tolerance Theory）

##### C：Consitency，一致性

该项强调数据的正确性. 具体而言，每次读操作，要么读到最新，要么读失败. 这要求整个分布式系统像是一个不可拆分的整体，写操作作用于集群像作用于单机一样，具有广义的“原子性”.

##### A：Availability，可用性

该项站在使用者的角度，强调使用服务的体验.客户端的请求能够得到响应，不发生错误，也不能出现过长的等待时间.

##### P：Partition tolerance，分区容错性

分区容错性强调的是，在网络环境不可靠的背景下，整个系统仍然是正常运作的，不至于出现系统崩溃或者秩序混乱的局面.

对于这三个性质，最多只能满足两个，所以在设计的时候需要tradeoff

对于一个分布式系统 P是必须要满足的，因此我们需要考虑到底是满足高可用还是强一致性。



##### C的问题

对于**即时一致性问题**，如果server端是异步的，那么client可能从某些节点中读到老数据。

试想一个场景：

I 当前集群的服务端有 master 和 follower 两个节点.

II 客户端写请求打到了 master，写入 x = 3 这一项内容；

III 紧接着，客户端读请求打到了 follower，查询 x = 3 的值.

那么在第（3）步中所取得的 x 的值会是多少呢？答案是不确定的. 因为这取决于 master 和 follower 之间数据同步的机制.

倘若，为了满足更快响应客户端的诉求，服务端采用了异步完成数据同步任务的机制，那么客户端的读请求就可能在 follower 同步到 set x = 3 这一项任务之前就打到 follower，此时会取到 x 的老数据或者 x 不存在的响应，总之，读到的数据和客户端期待的结果产生了差距.

以上，就是分布式系统中的即时一致性问题.



对于**顺序一致性问题**

现在请试想另一种场景：

###### **I 客户端依次向 master 发送了 set x = 3、set x = 4 的两笔请求；**

###### **II master 在本机依次完成了两笔写操作，于是状态机中记录的结果为 x = 4；**

###### **III 同时，master 异步开启将请求同步到 follower 的任务，任务发出的顺序也是 ① set x = 3 ② set x = 4；**

###### **IV 由于网络问题，第 ① 笔请求出了点状况，导致第 ② 笔请求后发先至，第 ① 笔请求随后而至；**

###### **V 于是 follower 先执行 ② set x = 4，后执行 ① set x = 3，最终 follower 状态机内的结果为 x = 3.**

这个问题相比场景（1）就更严重了，因为 follower 中已经记录了错误的数据，接下来不论何时面对客户端的读请求都会返回这个错误的结果. 这种情况下，我们就称分布式系统的最终一致性也遭到了破坏.



##### A的问题

（1）倘若集群中某个 follower 出现宕机, master 同步数据时会因为未集齐所有 follower 的响应, 而无法给客户端 ack，这样一个节点的问题就会被放大到导致整个系统不可用；

（2）倘若某个 follower 的网络环境或者本机环境出现问题，它给出同步数据响应的时间出乎意料的长，那么整个系统的响应效率都会被其拖垮，这就是所谓的木桶效应.



| **中文术语** | **英文术语**          | **含义**                                                     |
| ------------ | --------------------- | ------------------------------------------------------------ |
| 领导者       | leader                | 节点的三种角色之一. 集群的首脑，负责发起”提议“、”提交“被多数派认可的决断. |
| 跟随者       | follower              | 节点的三种角色之一. 需要对 leader 的 ”提议“ 、”提交“和 candidate 的 ”竞选“ 进行响应. |
| 候选人       | candidate             | 节点的三种角色之一. 是一种处于竞选流程中的临时状态，根据多数派投票的结果会切为 leader 或 follower 的稳定态. |
| 最终一致性   | finnal consistency    | 中强一致性. 对于写请求，服务端保证最终一定能提供出正确的结果，但需要同步时间. 同步期间，可能被读到不一致的老数据. |
| 即时一次性   | immediate consistency | 强一致性. 服务端要求做到写入立即可读.                        |
| 预写日志     | write ahead log       | 记录写请求明细的日志.（单指 raft 算法下狭义的预写日志）      |
| 状态机       | state machine         | 节点内存储数据的介质.                                        |
| 提议         | proposal              | 两阶段提交的第一个阶段. 指的是 leader 向所有节点发起日志同步请求的过程. |
| 提交         | commit                | 两阶段提交的第二个阶段. 指的是 leader 认可一笔写请求已经被系统采纳的动作. |
| 应用         | apply                 | 指的是将预写日志记录内记录的写操作应用到状态机的过程.        |
| 任期         | term                  | 任期是用于标识 leader 更迭的概念. 每个任期内至多只允许有一个 leader. |
| 日志索引     | index                 | 日志在预写日志数组中的位置.                                  |
| 脑裂         | brain split           | 同一任期内，集群出现两个 leader，导致秩序崩盘.               |



### Raft 一主多从 读写分离

raft中很多方面都遵循多数派原则，即系统的决断无需全员参与,多数派达成的共识即可视为整个系统的答复。

多数派原则是提高分布式系统可用性 A 的关键. 对于整个系统而言，执行一项操作要求全员共同响应以实现强 C 的保证是过于苛刻的，因为我们无法保证所有节点都能健康运作。

尽量保持节点个数为**奇数**。

**一主多从**： raft中分为leader和follower两类角色（先不管candidate），

leader拥有更广阔的视野，需要总览全局，领导一些日常事务的推进；

follower 职责相对简单但同样重要，因为这是一个基于多数派原则运作的民众团体，所有角色只要拧成一股绳，聚成了多数派，就能代表整个系统进行决断，甚至包括推翻 leader.

**读写分离**： 

读操作可以由集群的任意节点提供服务；

写操作统一需要由 leader 收口处理，并向 follower 同步. 倘若 follower 率先收到了来自客户端的写请求，也需要转发给 leader 进行处理.

这种读写分离的机制，通过读操作的负载均衡提高了系统整体的吞吐量，也通过写操作的统一收口降低了共识算法的复杂度，但与此同时也衍生出两个问题：

（1）读操作可由任意节点提供服务，那么倘若一个存在数据状态滞后的 follower 提供了服务，那么客户端就可能读到老数据. 因此到此为止，raft 只能保证到数据的最终一致性，而无法满足即时一致性. 

（2）集群一主多从，纵览全局. 倘若 leader 出了问题，群龙无首，系统岂不是会分崩离析吗？针对这个问题，raft 建立了一套完善的领导者选举机制，保证在 leader 不可用时会有替补席的 follower 挺身而出，改朝换代成为新的 leader，保证系统的正常运作。



### 状态机与预写日志

状态机 （state machine）是节点实际存储数据的容器,写请求的最后一步是将结果写入状态机，而读请求也需要从状态机中获取数据进行响应.

预写日志（write ahead log，简称 wal）是通过日志的方式记录下每一笔写请求的明细（例如 set x = 3 这样一笔记录），使得变更历史有迹可循. 在 raft 算法中，写请求会先组织成预写日志的形式添加到日志数组中，当一个日志（写请求）达到集群多数派的认可后，才能够被提交，将变更应用到状态机当中.

预写日志的设计是为了解决顺序一致性问题的：

预写日志由一个数组承载，为一段时间内的多笔写请求提供了一个缓存区；同时，每笔预写日志是一笔写请求的抽象，通过其记录的明细，使得我们可以对写请求的内容进行比较. 这样的机制之下，我们只要保证预写日志数组中，被准许应用到状态机的部分每笔预写日志的内容都完全相同，这样就能解决写请求乱序的问题，从而达成数据的最终一致性.



### 两阶段提交

->leader接收到一个写请求 
->leader将写请求添加到本地的预写日志中，并向其他节点广播同步这笔写请求，这个过程就称为proposal
->follower收到同步请求后通过一套校验机制来判断是否执行同步并返回响应
->若leader收到半数以上的节点同意并完成了他们本地的预写日志的操作，那么leader此时会commit这个请求，并返回ack给client表示已经成功处理请求。
->其他节点随后会通过与leader的其他交互方式中得到这个commit操作信息（etcd中使用heartbeat），最终commit操作被follower也执行。
->已经commit的预写日志具备了被apply到状态机中的资格，但apply的时机取决于实现方式，倘若只追求最终一致性，可以选择异步应用；倘若追求立即一致性，则会要求 leader 先应用到状态机，才能给予客户端 ack。

整个流程分为proposal和commit两个阶段，所以称之为两阶段提交

这里有个**小思考点**： 所有已经被commit的请求，从client视角来看，它已经被系统接收采纳，那么系统自身就应当完成这个最终一致性的任务。如果leader在收到来自follower同意将请求添加到预写日志之后，在leader本地实现了commit，然而此时leader突然宕机（意味着leader还没能将commit信息发送给follower）。那么此时，需要进行重新选举，由于此前大多数节点都已经将该笔请求写入到预写日志了，所以未写入的节点不会获得这些此前已经将请求写入到预写日志的节点的投票，因而他们无法成为新的leader。而新的leader一旦上任，他们就会去commit这些上个leader未commit的预写日志，并将这些commit信息发送给follower，以完成最终一致性。

### 领导者选举

国一日不可无君，家一日不可无主，raft不可一日无leader

leader是写请求的入口，所以如果leader寄了，必须要有一个选举机制来让follower成为新的leader，以保证集群的正常运作。

（1）follower 如何感应到 leader 挂了，从而主动进行补位？

leader 需要定期向 follower 发送心跳，证明自己仍然健在。与之对应的，follower 会建立一个心跳检测定时器，当超过指定时长未收到 leader 的心跳，则认为 leader 已死，会切换成候选人（candidate）发起竞选，尝试补位成为新的 leader。

（2）什么样的 follower 有资格补位成为 leader？

follower 成为 candidate 后,会广播向所有节点拉票，当投赞同票的节点数（包括candidate 本身）达到多数派的时候，该 candidate 会胜任，成为新的 leader. 

### 任期与日志索引

term就是一个任期，term是全局增大的，每一个任期中最多只有一个leader（也可能竞选失败而导致一个任期无leader），每次转换leader的时候，对应的term都会增大。

每当一个candidate发起一轮campaign（竞选）的时候，他都会在自己的term上自增1，相当于告诉其他人，自己要改朝换代了。

节点中的预写日志存放在一个数组中，每则日志在数组中的位置称之为索引 index.

于是，每一则预写日志会有两个核心的标识属性：

（1）term：标志了这则日志是哪个任期的 leader 在位时同步写入的；

（2）index：标志了这则日志在预写日志数组的位置.

通过 {term , index} 二元组可以组成一个全局唯一键，定位到一则日志，并且能够保证位于不同节点中日志，只要其 term 和 index 均相同，其内容一定完全一致。



### 角色定义及切换

raft 算法中，集群节点的角色类型分为：领导者 leader、跟随者 follower、候选人 candidate 三种角色.

（1）leader -> follower

倘若 leader 发现当前系统中出现了更大的任期，则会进行“禅让”，主动退位成 follower.

这里 leader 发现更大任期的方式包括：I 向 follower 提交日志同步请求时,从 follower 的响应参数中获得; II 收到了来自新任 leader 的心跳或者同步日志请求；III 收到了任期更大的 candidate 的拉票请求.

（2）follower -> candidate

leader 需要定期向 follower 发送心跳，告知自己仍健在的消息.

倘若 follower 超过一定时长没收到 leader 心跳时，会将状态切换为 candidate ，在当前任期的基础上加 1 作为竞选任期，发起竞选尝试补位.

（3）candidate -> follower

candidate 参与竞选过程中，出现以下两种情形时会退回 follower：

I 多数派投了反对票；

II 竞选期间，收到了任期大于等于自身竞选任期的 leader 传来的请求.

（4）candidate -> leader

candidate 竞选时，倘若多数派投了赞同票，则切换为 leader.

（5）candidate -> candidate

candidate 的竞选流程有一个时间阈值. 倘若超时仍未形成有效结论（多数派赞同或拒绝），则会维持 candidate 身份，将竞选任期加1，发起新一轮竞选.

#### Leader

1. 定期广播心跳请求。 让 follower 重置心跳检测定时器，避免其切换成 candidate 发起竞选，在心跳请求中携带上 leader 最新已提交日志的标识 id（term + index），推动 follower 更新日志提交进度。

   etcd中 follower会回复心跳请求，让leader来判断自己的地位是否正常。

2. propose log synchronization， 广播proposal，开启两阶段提交流程。

#### Follower

follower的职责：

（1）负责同步 leader 传来的写请求，此时也有一个参与民主反馈的过程，倘若同步成功，会给予 leader 正向反馈，当 leader 的同步请求收到半数以上的认可时，会提交日志；

（2）通过接收 leader 心跳的方式，获取到携带的 commitIndex 信息，及时完成已被多数派认可的预写日志的提交，以推进其写入状态机的进度. 这一项相当于做到了数据的备份，也被读请求最终一致性提供了保证;

（3）负责为参与竞选 candidate 的投票

（4）通过心跳检测定时器时时关注 leader 的健康状态，当超时未收到心跳时，会切换为 candidate 发起竞选.

#### Candidate

candidate 是一个临时态，成为 candidate 意味着此时正处于成与败的分叉路口，candidate 有关的核心流程如下：

（1）倘若 follower 切为 candidate，会将当前任期加1，作为竞选任期；

（2）会将自身的一票投给自己；

（3）广播向所有节点拉票；

（4）倘若拉票请求超时前，得到多数派认可，则上位为 leader；

（5）倘若拉票请求超时前，遭到多数派拒绝，则老实退回 follower；

（6）倘若拉票请求超时前，收到了任期大于等于自身竞选任期的 leader 的请求，则老实退回 follower；

（7）倘若拉票请求超时，则竞选任期加 1，发起新一轮竞选拉票请求.



#### 请求链路梳理

